{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d5143b-d5b4-4788-befb-50da4c3f3f97",
   "metadata": {},
   "source": [
    "# YouTube AI Agent\n",
    "## ABB #8 - Session 4\n",
    "\n",
    "Code authored by: Shaw Talebi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23470da-9b3e-44a8-b18a-4ccc8f5ba32a",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7514679-c195-4bf9-bad3-0f7a26a0d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "from agents import Agent, function_tool, run_demo_loop\n",
    "from dotenv import load_dotenv\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777be3cb-f501-45c1-a97d-064bbc73b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbe3d3-a590-45eb-be46-52791873b23f",
   "metadata": {},
   "source": [
    "### define instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d50a5039-d46a-4cbb-90a0-22999a164df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You provide help with tasks related to YouTube videos.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb81b6f-aa66-425c-b1a9-d099f0c82c45",
   "metadata": {},
   "source": [
    "### define tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d186d1d6-2950-4cec-8bda-d44321dbbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def fetch_youtube_transcript(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract transcript with timestamps from a YouTube video URL and format it for LLM consumption\n",
    "    \n",
    "    Args:\n",
    "        url (str): YouTube video URL\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted transcript with timestamps, where each entry is on a new line\n",
    "             in the format: \"[MM:SS] Text\"\n",
    "    \"\"\"\n",
    "    # Extract video ID from URL\n",
    "    video_id_pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    video_id_match = re.search(video_id_pattern, url)\n",
    "    \n",
    "    if not video_id_match:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "    \n",
    "    video_id = video_id_match.group(1)\n",
    "    \n",
    "    try:\n",
    "        ytt_api = YouTubeTranscriptApi()\n",
    "        transcript = ytt_api.fetch(video_id)\n",
    "        \n",
    "        # Format each entry with timestamp and text\n",
    "        formatted_entries = []\n",
    "        for entry in transcript:\n",
    "            # Convert seconds to MM:SS format\n",
    "            minutes = int(entry.start // 60)\n",
    "            seconds = int(entry.start % 60)\n",
    "            timestamp = f\"[{minutes:02d}:{seconds:02d}]\"\n",
    "\n",
    "            formatted_entry = f\"{timestamp} {entry.text}\"\n",
    "            formatted_entries.append(formatted_entry)\n",
    "        \n",
    "        # Join all entries with newlines\n",
    "        return \"\\n\".join(formatted_entries)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error fetching transcript: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e213b4-c41b-4dc8-9213-c79ae13b2108",
   "metadata": {},
   "source": [
    "### create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a0ce90-c098-44e9-a823-182e71576bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"YouTube Transcript Agent\",\n",
    "    instructions=instructions,\n",
    "    tools=[fetch_youtube_transcript],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae7380-3e0d-4846-8fff-abb2d462bdb8",
   "metadata": {},
   "source": [
    "### main() function\n",
    "\n",
    "[Example](https://github.com/ShawhinT/AI-Builders-Bootcamp-6/blob/main/session-4/example_1-youtube_agent.ipynb) with custom CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86d9958-aeeb-49cd-9270-6b53b6929aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    await run_demo_loop(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d78925-f897-43dd-8497-87760fa01983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " >  what is this video about? https://youtu.be/ZaY5_ScmiFE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent updated: YouTube Transcript Agent]\n",
      "\n",
      "[tool called]\n",
      "\n",
      "[tool output: [00:00] Hey everyone, I'm Shaw. This is the\n",
      "[00:02] first video in a larger series on AI\n",
      "[00:05] agents. Here I'll start by discussing\n",
      "[00:07] what an AI agent actually is and why we\n",
      "[00:10] should care about them. Then I'll review\n",
      "[00:12] three common types of agents at various\n",
      "[00:15] levels of agency. 2025 is said to be the\n",
      "[00:19] year of AI agents. Yet for many people\n",
      "[00:22] that I've talked to, it's not entirely\n",
      "[00:25] clear what this actually means. Part of\n",
      "[00:28] the problem is that no one can seem to\n",
      "[00:31] agree on a single definition for AI\n",
      "[00:35] agents. To demonstrate this, here are\n",
      "[00:36] some definitions from a few leading\n",
      "[00:39] organizations. Open AAI in their agents\n",
      "[00:41] SDK documentation defines an agent as a\n",
      "[00:45] large language model configured with\n",
      "[00:47] instructions and tools. This is\n",
      "[00:49] different from say hugging faces\n",
      "[00:51] definition from their transformers\n",
      "[00:54] documentation which describes it as a\n",
      "[00:56] system where a large language model can\n",
      "[00:58] execute more complex tasks through\n",
      "[01:01] planning and using tools. So here\n",
      "[01:04] there's a subtle difference. Open AI's\n",
      "[01:06] definition is focused on tools. That's\n",
      "[01:08] like the main thing. While hugging face\n",
      "[01:10] they talk about tools but they also\n",
      "[01:12] mention planning which is basically\n",
      "[01:14] taking a user's query or an input\n",
      "[01:17] breaking the task down or the problem\n",
      "[01:20] down into specific steps and then\n",
      "[01:23] executing it. And then if we look at\n",
      "[01:24] anthropics definition and so this is\n",
      "[01:26] from a blog post called building\n",
      "[01:28] effective agents where they define it as\n",
      "[01:31] systems where LLMs dynamically direct\n",
      "[01:34] their own processes and tool usage\n",
      "[01:36] maintaining control over how they\n",
      "[01:38] accomplish tasks. So again we see this\n",
      "[01:40] mention of tool usage. However,\n",
      "[01:42] anthropics definition seems to be\n",
      "[01:44] primarily focused on autonomy. Basically\n",
      "[01:48] LLM systems that have complete control\n",
      "[01:51] over how they do things. So, I won't try\n",
      "[01:54] to make things even worse by proposing\n",
      "[01:56] yet another definition, but instead I\n",
      "[01:58] want to talk about three key features\n",
      "[02:00] that come up regardless of the specific\n",
      "[02:03] definition that people might give to\n",
      "[02:06] agents. So, first and foremost, there's\n",
      "[02:08] always an LLM involved. So, in those\n",
      "[02:10] three definitions we saw in the previous\n",
      "[02:12] slide and all the other definitions I've\n",
      "[02:14] seen, LLMs play a central role in what\n",
      "[02:18] people are calling AI agents today. So,\n",
      "[02:20] it's going to be an LLM represented by\n",
      "[02:22] this robot emoji and then some other\n",
      "[02:24] stuff, some software you write around\n",
      "[02:27] it. Maybe you use a framework or you\n",
      "[02:28] code it from scratch. But there's some\n",
      "[02:30] other stuff that kind of augments the\n",
      "[02:32] LLM. The next thing is tool use. So,\n",
      "[02:35] this can be something like a web search,\n",
      "[02:36] a Python interpreter, memory, sending an\n",
      "[02:40] email, or even access to a different\n",
      "[02:42] large language model that is specialized\n",
      "[02:44] for a particular task. And I'll talk\n",
      "[02:46] about why tool usage is so important for\n",
      "[02:49] agents on the next slide. And then\n",
      "[02:51] finally there is usually some mention of\n",
      "[02:55] autonomy. So we saw in hugging faces\n",
      "[02:58] definition there was this notion of\n",
      "[03:00] planning and anthropics definition which\n",
      "[03:02] we'll talk more about. They really\n",
      "[03:04] stress the importance of these like open\n",
      "[03:07] loops. This ability for the model to\n",
      "[03:11] reflect on its outputs and get real\n",
      "[03:14] world feedback on them. Another thing\n",
      "[03:16] this might include is the so-called\n",
      "[03:18] reasoning capabilities of LLMs like\n",
      "[03:21] DeepSeek R1 or OpenAI's 01 or 03 models.\n",
      "[03:26] This ability for LLMs to quote unquote\n",
      "[03:28] think before providing an answer allows\n",
      "[03:31] it to accomplish more and more complex\n",
      "[03:33] tasks without explicit instructions. And\n",
      "[03:36] so everyone is very excited about agents\n",
      "[03:39] these days. People are saying 2025 is\n",
      "[03:41] the year of AI agents. YC is saying that\n",
      "[03:43] vertical AI agents could be 10 times\n",
      "[03:46] bigger than SAS. And this might be very\n",
      "[03:48] reminiscent to a couple years ago when\n",
      "[03:50] chatbt came out and there was a lot of\n",
      "[03:53] excitement around LLMs and specifically\n",
      "[03:55] building chatbots. Back then I had\n",
      "[03:57] people reaching out to me all the time\n",
      "[03:59] saying how they wanted to build some\n",
      "[04:00] kind of chatbot for their company for\n",
      "[04:02] some specific use case. And then fast\n",
      "[04:05] forward one year later, a sentiment I\n",
      "[04:06] heard from a lot of business leaders or\n",
      "[04:09] business operators is that they weren't\n",
      "[04:11] able to get ROI from these chatbots. And\n",
      "[04:14] so they might be thinking it's just a\n",
      "[04:16] repeat of this is just like another hype\n",
      "[04:18] thing that isn't going to generate\n",
      "[04:20] return on investment. While there's a\n",
      "[04:22] lot to unpack there, the key difference\n",
      "[04:24] between agents and chat bots is that\n",
      "[04:26] LLMs alone aren't enough to solve most\n",
      "[04:30] real world problems. And so there are\n",
      "[04:32] two key things that I would say make\n",
      "[04:33] agents much more valuable than just\n",
      "[04:36] vanilla chat bots like the original\n",
      "[04:38] version of chat GBT. So the first is\n",
      "[04:40] that agents can interact with reality\n",
      "[04:43] through tool use. LLMs just out of the\n",
      "[04:46] box they don't live in reality. They\n",
      "[04:48] live in an imagined reality. They live\n",
      "[04:51] in some kind of imagination land. This\n",
      "[04:53] is why hallucinations are a big problem\n",
      "[04:55] with LLMs. And then if you asked one of\n",
      "[04:57] these LLMs to write you some Python code\n",
      "[04:59] and execute it, it would just make up\n",
      "[05:02] the outputs. It wouldn't actually run\n",
      "[05:04] the code because LLMs can only generate\n",
      "[05:06] text. They can't run code. They can't do\n",
      "[05:09] web search. They can't do a lot of\n",
      "[05:10] useful things to get feedback from the\n",
      "[05:13] real world to make them more useful. So\n",
      "[05:16] tools take LLMs from their imagination\n",
      "[05:20] land based on their pre-training data\n",
      "[05:22] and put them in the real world. kind of\n",
      "[05:25] give them real world feedback, real\n",
      "[05:27] world context. Another reason why agents\n",
      "[05:29] are inherently more valuable than the\n",
      "[05:32] vanilla chat bots we've seen in the past\n",
      "[05:34] is this discovery of so-called testime\n",
      "[05:37] compute scaling. And this is just a\n",
      "[05:39] fancy way of saying that the more tokens\n",
      "[05:41] an LLM generates, the better its\n",
      "[05:45] responses. So this is the whole idea of\n",
      "[05:47] giving models time to think about\n",
      "[05:50] problems, allowing them to kind of\n",
      "[05:52] reason about problems, come up with an\n",
      "[05:54] action plan before giving their final\n",
      "[05:57] answer. And so today with models like 01\n",
      "[05:59] and Deepseek R1 which are trained using\n",
      "[06:01] reinforcement learning, now we have\n",
      "[06:03] models which are much more capable of\n",
      "[06:05] solving arbitrary tasks without explicit\n",
      "[06:08] instructions than before. And this\n",
      "[06:11] ability to just oneshot novel problems\n",
      "[06:14] is actually very valuable for agents\n",
      "[06:17] because now you don't have to write very\n",
      "[06:19] sophisticated and detailed prompts for\n",
      "[06:22] specific problems. These models can\n",
      "[06:24] solve a wider range of tasks. Well, and\n",
      "[06:27] if you're not familiar with this test\n",
      "[06:28] time compute and you know reasoning\n",
      "[06:30] models and all that, I talked all about\n",
      "[06:32] that in a previous video which I'll link\n",
      "[06:33] here in case you are interested. Since\n",
      "[06:36] no one can seem to agree on a single\n",
      "[06:38] definition for AI agents, most\n",
      "[06:40] practitioners I talk to don't really\n",
      "[06:42] worry so much if a system is an AI agent\n",
      "[06:45] or not, but rather they just talk about\n",
      "[06:47] agentic systems. Basically conveying\n",
      "[06:50] this idea that agency is on a spectrum.\n",
      "[06:53] In other words, you can have systems\n",
      "[06:54] with no agency. So basically like a\n",
      "[06:57] rule-based system where the logic is\n",
      "[06:59] hard-coded all the way to a system that\n",
      "[07:02] has human level agency. And so here I'm\n",
      "[07:05] going to convey this idea by talking\n",
      "[07:07] about three systems at increasing levels\n",
      "[07:10] of agency. So level one is an LLM plus\n",
      "[07:14] tools. Level two are LLM workflows and\n",
      "[07:17] level three is an LLM in a loop. So tool\n",
      "[07:20] use is a central feature of any agentic\n",
      "[07:23] system. And the main thing here is that\n",
      "[07:25] tools expand the capabilities of LLMs\n",
      "[07:28] beyond text completion. Two common tools\n",
      "[07:31] that you might give an LLM are web\n",
      "[07:33] search and a code interpreter. And so\n",
      "[07:36] these two tools kind of fill in two\n",
      "[07:39] major blind spots of an LLM. For LLMs\n",
      "[07:42] out of the box, their understanding of\n",
      "[07:44] the world is based on a snapshot from\n",
      "[07:47] like 12 months ago, which was captured\n",
      "[07:49] by their pre-training data. And of\n",
      "[07:52] course, the world has changed a lot over\n",
      "[07:53] the past 12 months or so. So if you were\n",
      "[07:56] to ask an LLM about anything recent, it\n",
      "[07:58] would basically just make something up.\n",
      "[08:00] This is where web search can help. You\n",
      "[08:02] can give the model access to a tool like\n",
      "[08:06] web search and then you can train it to\n",
      "[08:08] identify when it receives requests where\n",
      "[08:12] web search is going to be a helpful\n",
      "[08:15] thing to do. Another really handy tool\n",
      "[08:17] is a code interpreter. This allows LLM\n",
      "[08:20] to do a lot of different tasks. for\n",
      "[08:23] example, doing math, which is something\n",
      "[08:25] that LLMs really struggle with. Instead\n",
      "[08:27] of basically the LLM trying to do the\n",
      "[08:30] math in its head, it can write some\n",
      "[08:31] Python code to do some complicated\n",
      "[08:33] arithmetic and it can send that code to\n",
      "[08:36] its Python interpreter. The code can\n",
      "[08:38] actually be run and the results can be\n",
      "[08:40] sent back to the LLM. And no, without\n",
      "[08:42] the code interpreter, the LLM would\n",
      "[08:44] still be able to write code. It just\n",
      "[08:46] wouldn't be able to run it. So, it would\n",
      "[08:48] basically make up the outputs. And so\n",
      "[08:50] these are two very fundamental tools,\n",
      "[08:52] but there are many others that you could\n",
      "[08:54] use. So another big one are API calls.\n",
      "[08:57] So maybe you want to fetch information\n",
      "[08:59] from YouTube or you might want to\n",
      "[09:01] connect to Gmail. So maybe you want the\n",
      "[09:03] LLM to be able to read your emails or to\n",
      "[09:05] write emails on your behalf. Or even you\n",
      "[09:08] might have like a notion page where you\n",
      "[09:11] have a lot of notes and you want the LLM\n",
      "[09:13] to be able to access those notes and do\n",
      "[09:15] some kind of task that is helpful to\n",
      "[09:17] you. And so notice the API calls go both\n",
      "[09:19] ways. They can both be used to give the\n",
      "[09:22] LLM real world context, real world\n",
      "[09:25] information, and they can also be used\n",
      "[09:28] to allow the model to take actions in\n",
      "[09:31] the real world, which are two essential\n",
      "[09:33] components of agency. Another popular\n",
      "[09:35] one is computer use. Not every program\n",
      "[09:38] you care about has an API, basically has\n",
      "[09:41] a programmatic way of interacting with\n",
      "[09:43] it, but it does have a graphical user\n",
      "[09:45] interface. So computer use enables LLMs\n",
      "[09:49] to interact with these graphical\n",
      "[09:51] interfaces using mouse clicks and\n",
      "[09:53] keyboard strokes. Another tool could be\n",
      "[09:55] another model. So for example, ChadByt\n",
      "[09:58] has access to a text to image model. So\n",
      "[10:01] if you ask it to create an image for\n",
      "[10:03] you, it can take that request, pass it\n",
      "[10:06] to this external model, and then take\n",
      "[10:08] that resulting image and show it to you.\n",
      "[10:10] Another tool might be rag. So instead of\n",
      "[10:13] searching the internet, maybe you just\n",
      "[10:15] want to search an internal knowledge\n",
      "[10:17] base or over a set of documents or\n",
      "[10:20] something like that. So that's where RAD\n",
      "[10:21] can be helpful. And then another helpful\n",
      "[10:23] tool is memory, which allows the system\n",
      "[10:26] to retain important information over a\n",
      "[10:29] long time period. So this could be over\n",
      "[10:32] multiple LLM calls or even over multiple\n",
      "[10:35] conversations. So, while this level one\n",
      "[10:38] agent of LLM plus tools matches OpenAI's\n",
      "[10:41] definition, many people I've talked to\n",
      "[10:43] wouldn't consider this a quote unquote\n",
      "[10:46] AI agent, the core limitation of systems\n",
      "[10:49] like this is that you're basically\n",
      "[10:51] relying on a single model and a single\n",
      "[10:54] thread of information to solve whatever\n",
      "[10:57] task you're trying to do. And so, while\n",
      "[10:59] this works fine for one-off tasks or\n",
      "[11:01] small tasks, as the requests get more\n",
      "[11:04] complicated, this can start to break\n",
      "[11:05] down. Like for example, if I wanted a\n",
      "[11:08] system to like end to end write blogs\n",
      "[11:10] for me, so basically come up with blog\n",
      "[11:12] ideas, pick out the best one, write a\n",
      "[11:15] first draft or something like that. This\n",
      "[11:17] might be hard for a single model to do\n",
      "[11:20] well, even if it does have access to\n",
      "[11:22] like web search to do research and a\n",
      "[11:24] library of like past blogs and past\n",
      "[11:27] topics or something like that. This\n",
      "[11:28] brings us to level two, which are LLM\n",
      "[11:31] workflows. And so most of the agentic\n",
      "[11:34] systems that you'll see these days are\n",
      "[11:37] this kind of system. So frameworks like\n",
      "[11:40] langraph and llama index are really\n",
      "[11:42] optimized for building these kinds of\n",
      "[11:44] agentic systems. And so all a LLM\n",
      "[11:47] workflow is is a predefined sequence of\n",
      "[11:49] steps with at least one LLM involved. To\n",
      "[11:52] give a concrete example, let's say I\n",
      "[11:54] wanted an agentic system, an AI agent to\n",
      "[11:57] help me respond to emails. Instead of\n",
      "[12:00] just taking an LLM, giving it very\n",
      "[12:02] detailed instructions, and giving it\n",
      "[12:04] access to my Gmail, like the level one\n",
      "[12:06] system, I might define a workflow like\n",
      "[12:08] this to kind of make the system a bit\n",
      "[12:11] more reliable. So, the workflow would\n",
      "[12:13] look something like this. An email comes\n",
      "[12:15] into my inbox. Then, this LLM would spit\n",
      "[12:17] up and it would categorize the email.\n",
      "[12:20] Basically, it would see if it's junk or\n",
      "[12:22] not junk. If it's junk, the system would\n",
      "[12:24] move it to the trash. If it's not junk,\n",
      "[12:26] I could pass it to another LLM to decide\n",
      "[12:29] if it's a hard email to respond to or\n",
      "[12:32] just like a easy email to respond to.\n",
      "[12:35] So, if it's just like a sounds great,\n",
      "[12:36] thanks, or an email that I've written\n",
      "[12:39] many times before, and there's like a\n",
      "[12:41] template for it or something like that,\n",
      "[12:42] it can make that decision. Notice we\n",
      "[12:44] could have just had one LLM do this\n",
      "[12:46] categorization where we have one LLM\n",
      "[12:48] that decides whether the email is junk,\n",
      "[12:51] an easy response, or hard response. But\n",
      "[12:54] this is a more complicated task. So it's\n",
      "[12:56] going to be harder for a LLM to do in\n",
      "[12:59] just one shot. So by splitting this\n",
      "[13:01] complex task into two simpler tasks, we\n",
      "[13:04] actually make it easier for each of\n",
      "[13:06] these LLMs. And maybe you don't even\n",
      "[13:08] need to use an LLM here. Maybe you can\n",
      "[13:10] just use a fine-tuned text classifier to\n",
      "[13:12] do the junk not junk. But then maybe\n",
      "[13:14] this categorization is a bit more\n",
      "[13:16] difficult and harder to gather training\n",
      "[13:18] data for. So an LLM is better suited\n",
      "[13:21] here. Okay. But then going on with the\n",
      "[13:22] workflow, if it's a hard response, the\n",
      "[13:24] system can just leave it for me to\n",
      "[13:26] respond to. If it's an easy response, it\n",
      "[13:28] can get passed to a LLM email writer\n",
      "[13:31] that specializes in this, and then that\n",
      "[13:33] LLM can send an email. And so the key\n",
      "[13:36] difference between level one and level\n",
      "[13:38] two is that we're no longer limited to\n",
      "[13:39] just a single LLM with access to some\n",
      "[13:42] tools, but rather we can have multiple\n",
      "[13:45] of these LLM plus tool systems working\n",
      "[13:48] together to solve more and more complex\n",
      "[13:50] tasks with better performance. And so\n",
      "[13:53] there are really countless ways you can\n",
      "[13:55] design LLM workflows. Some are going to\n",
      "[13:57] have more agency than others, but\n",
      "[13:59] there's this really nice blog post by\n",
      "[14:01] Anthropic. It's reference number three.\n",
      "[14:03] It's called Building Effective Agents.\n",
      "[14:05] And there they break down various common\n",
      "[14:08] design patterns for these workflows. So\n",
      "[14:10] I just wanted to mention those here. So\n",
      "[14:12] the first one is chaining. So this is\n",
      "[14:14] like a very simple design. You have\n",
      "[14:16] module A passes output to module B which\n",
      "[14:18] passes output to module C. So maybe you\n",
      "[14:21] have a system that is going to write\n",
      "[14:22] blog posts for you. So you have one\n",
      "[14:25] module just coming up with ideas.\n",
      "[14:27] Another module deciding what ideas are\n",
      "[14:29] good and what ideas are bad. And then\n",
      "[14:31] you have a third module that writes the\n",
      "[14:33] first draft of that blog post. And\n",
      "[14:35] again, you could probably have a single\n",
      "[14:37] model do this, but it probably wouldn't\n",
      "[14:39] perform as well as a system that breaks\n",
      "[14:41] it into more specialized roles. Another\n",
      "[14:44] common design is routing. So this is\n",
      "[14:47] something we saw in the example I shared\n",
      "[14:49] on the previous slide where you have\n",
      "[14:50] like this classification step and a fork\n",
      "[14:53] in the workflow. So let's say you have\n",
      "[14:55] an email come in and you want to\n",
      "[14:57] classify it as junk and not junk. And\n",
      "[15:00] that's because you want to treat these\n",
      "[15:01] two different types of inputs\n",
      "[15:03] differently. Another common design is\n",
      "[15:05] what Anthropic called parallelization.\n",
      "[15:08] So there are two kinds of\n",
      "[15:09] parallelization. The first one is\n",
      "[15:10] sectioning. Sectioning is when you take\n",
      "[15:12] a task and you split it into various\n",
      "[15:16] subtasks that can actually be run at the\n",
      "[15:18] same time. A good example of this is say\n",
      "[15:20] a user types in a request into a chat\n",
      "[15:23] interface and let's say to process this\n",
      "[15:25] request you need two things to happen.\n",
      "[15:28] one, you need the LLM to generate a\n",
      "[15:30] response, and two, you need to make sure\n",
      "[15:32] the request is appropriate and abides by\n",
      "[15:35] your terms of use or some set of rules\n",
      "[15:38] that you have for your application. So,\n",
      "[15:41] you can actually run these tasks at the\n",
      "[15:43] same time because they're not dependent\n",
      "[15:45] on each other. And this will result in\n",
      "[15:47] lower latency because you don't have to\n",
      "[15:49] check if the query abides by the rules\n",
      "[15:51] and then generate a response to it. You\n",
      "[15:53] can just do these at the same time and\n",
      "[15:55] then generate the response. Another\n",
      "[15:57] version of parallelization is voting. So\n",
      "[16:00] let's say you have some kind of lead\n",
      "[16:02] scoring system. You want to grade leads\n",
      "[16:04] as like lowquality, medium quality, high\n",
      "[16:07] quality or something like that. But this\n",
      "[16:09] is a pretty hard task where a single LLM\n",
      "[16:12] might get it wrong like 60 or 70% of the\n",
      "[16:15] time. But one way you can kind of\n",
      "[16:16] overcome this is instead of just giving\n",
      "[16:18] it to one LLM, you can give it to 10\n",
      "[16:20] LLMs. the same task of score this lead\n",
      "[16:23] and then you can aggregate the responses\n",
      "[16:27] of all 10 LLMs to give your final\n",
      "[16:30] result. The key upside here is that you\n",
      "[16:32] can improve the performance of your\n",
      "[16:35] agentic system while here you can\n",
      "[16:37] improve the speed of your agentic\n",
      "[16:40] system. Another common design is this\n",
      "[16:43] orchestrator workers paradigm where\n",
      "[16:46] instead of just having a rigid workflow\n",
      "[16:48] like we saw in the previous slide where\n",
      "[16:50] basically everything was predefined and\n",
      "[16:52] we have some agency within the LLM\n",
      "[16:55] modules because they have the freedom to\n",
      "[16:57] perform that specific task in whatever\n",
      "[16:59] way they like. This may not work for\n",
      "[17:02] tasks which are a bit less predictable\n",
      "[17:04] where you don't have a clear workflow\n",
      "[17:06] for all possible requests. In this\n",
      "[17:09] orchestrator workers design, you first\n",
      "[17:11] have the request go to a planning LLM.\n",
      "[17:14] This could be a really smart LLM that\n",
      "[17:16] can reason and think through problems.\n",
      "[17:18] And basically its only job is to come up\n",
      "[17:21] with the workflow to come up with the\n",
      "[17:24] plan of solving this problem or\n",
      "[17:26] performing this task. And then based on\n",
      "[17:28] that plan, the tasks are delegated to\n",
      "[17:32] separate systems. So to multiple LLMs or\n",
      "[17:35] maybe to some predefined code components\n",
      "[17:38] that tend to come up a lot for your\n",
      "[17:40] specific use case. So this is kind of\n",
      "[17:43] analogous to how you might have a single\n",
      "[17:45] LLM think step by step through a problem\n",
      "[17:49] and then solve the problem, but instead\n",
      "[17:51] of everything happening within one LLM,\n",
      "[17:53] you can spread this task among multiple\n",
      "[17:55] LLMs to potentially get better\n",
      "[17:57] performance. Finally, we have the\n",
      "[17:59] evaluator optimizer paradigm. The way\n",
      "[18:02] this works is that you have an LLM that\n",
      "[18:04] generates some response or some output\n",
      "[18:06] and then you have another system review\n",
      "[18:09] that response and give feedback. And\n",
      "[18:11] basically this loop can continue until\n",
      "[18:13] some stopping criteria are satisfied and\n",
      "[18:16] then it goes to the next step of the\n",
      "[18:19] workflow. This evaluator optimizer\n",
      "[18:21] pattern is fundamentally different than\n",
      "[18:24] all the other patterns that we're seeing\n",
      "[18:26] here. And the difference is that\n",
      "[18:28] everything else has a clear beginning\n",
      "[18:30] and end. It starts at point A and it\n",
      "[18:32] ends at point B and you know even if\n",
      "[18:34] you're splitting it up to operate in\n",
      "[18:36] parallel there's a clear end point.\n",
      "[18:39] However, because the evaluator optimizer\n",
      "[18:42] is this loop this could you know in\n",
      "[18:44] principle just go on indefinitely. So\n",
      "[18:47] inherently this system is capable of\n",
      "[18:50] doing tasks with more autonomy with more\n",
      "[18:52] agency than the other ones because we\n",
      "[18:55] haven't created these constraints or\n",
      "[18:59] rails for the system to operate on. It\n",
      "[19:02] basically figures out what it wants to\n",
      "[19:04] do by itself. This brings us to the\n",
      "[19:06] level three example which I call an LLM\n",
      "[19:09] in a loop. The idea here is giving an\n",
      "[19:12] LLM real world feedback on responses\n",
      "[19:15] until they are satisfactory. So to give\n",
      "[19:18] a concrete example, let's say I wanted\n",
      "[19:20] to have an LLM system, an AENTIC system\n",
      "[19:23] write LinkedIn posts for me. So I might\n",
      "[19:25] have an LLM writer. It's going to write\n",
      "[19:27] a LinkedIn post for me. And then what\n",
      "[19:29] I'm going to do is pass this post\n",
      "[19:30] through various sets of evaluations, you\n",
      "[19:33] know. So, the first thing I'm going to\n",
      "[19:34] do is see if that post is similar to my\n",
      "[19:37] existing posts because I want it to\n",
      "[19:40] sound like me and I want it to be\n",
      "[19:42] relevant to the other things that I've\n",
      "[19:43] talked about. Another evaluation I might\n",
      "[19:45] do is pass it through a AI post\n",
      "[19:48] detection system. That's because I don't\n",
      "[19:50] want the post to sound like an AI wrote\n",
      "[19:52] it. I want it to sound humanlike. And\n",
      "[19:54] then finally, I can evaluate if the\n",
      "[19:56] LinkedIn post is actually similar to the\n",
      "[19:59] initial idea that I fed into this LLM\n",
      "[20:03] system. And so then each of these\n",
      "[20:05] evaluations, we'll have like a pass\n",
      "[20:07] fail. And then we can have some logic\n",
      "[20:09] where if any of these evaluations\n",
      "[20:11] failed, we'll gather all the feedback\n",
      "[20:13] and we'll pass it back to the LLM\n",
      "[20:15] writer. We might say, okay, the post was\n",
      "[20:17] relevant to the idea, but it sounded AI\n",
      "[20:20] generated. you know, like 80% was AI\n",
      "[20:23] generated and it didn't really match the\n",
      "[20:25] voice of my existing posts. So, we kind\n",
      "[20:28] of gather all this feedback, give back\n",
      "[20:30] to the LLM, and then the LLM can go,\n",
      "[20:31] \"Oh, okay. So, I got this feedback.\n",
      "[20:33] Here's the post I just wrote. Let me\n",
      "[20:35] update it and write another one.\" And\n",
      "[20:37] then that'll spit out another LinkedIn\n",
      "[20:39] post. It'll go through the same\n",
      "[20:40] evaluations. And then again, if any of\n",
      "[20:42] them fail, we'll gather the feedback,\n",
      "[20:44] give it to the LLM, and continue in this\n",
      "[20:46] loop like this. And so the value of\n",
      "[20:47] these systems is that they can perform\n",
      "[20:49] very open-ended tasks. Let's say if I\n",
      "[20:52] wanted an LLM to write a LinkedIn post\n",
      "[20:53] for me, I might have to optimize the\n",
      "[20:56] prompt for a very specific idea or very\n",
      "[20:59] specific set of ideas for it to perform\n",
      "[21:01] well. While it might work well on those\n",
      "[21:03] examples, it's going to be fundamentally\n",
      "[21:06] limited because, you know, maybe it has\n",
      "[21:07] to follow a certain template or maybe it\n",
      "[21:09] needs like a reference document to write\n",
      "[21:12] the post from and all these other\n",
      "[21:14] constraints. But doing it in this way\n",
      "[21:16] where we're just giving the model\n",
      "[21:18] feedback, evaluating it based on these\n",
      "[21:21] outcomes that I care about, it can\n",
      "[21:23] potentially figure out the best post to\n",
      "[21:26] write through this closed loop. And then\n",
      "[21:28] if all the tests pass, we can return the\n",
      "[21:31] post. And so there's actually another\n",
      "[21:32] version of this. As I'm showing the\n",
      "[21:34] example here, we are just using the LLM\n",
      "[21:37] out of the box. And then we're just\n",
      "[21:38] getting very clever on how we define\n",
      "[21:40] these evaluations to design this system.\n",
      "[21:43] However, we could also do something\n",
      "[21:45] similar where we actually update the\n",
      "[21:48] internal parameters of the LLM. In other\n",
      "[21:50] words, we fine-tune the LLM to be\n",
      "[21:54] optimized in solving this task. So, the\n",
      "[21:57] model can get better and better the more\n",
      "[22:00] posts that it writes. This is the idea\n",
      "[22:02] of using end-to-end reinforcement\n",
      "[22:04] learning on realworld feedback in\n",
      "[22:07] optimizing an LLM system. The only\n",
      "[22:10] difference here is that we make the\n",
      "[22:12] parameters trainable and then we use an\n",
      "[22:14] algorithm like group relative policy\n",
      "[22:16] optimization to update the internal\n",
      "[22:18] parameters. And if you don't know what\n",
      "[22:20] I'm talking about with reinforcement\n",
      "[22:21] learning or group relative policy\n",
      "[22:23] optimization, I talked about that in a\n",
      "[22:25] previous video on reasoning models like\n",
      "[22:28] 01 and R1. While this might sound like\n",
      "[22:30] some kind of research project or\n",
      "[22:32] something like that, this is actually\n",
      "[22:33] the approach behind models like deep\n",
      "[22:36] research which is currently available in\n",
      "[22:38] chatbt and also openai's operator model\n",
      "[22:42] which is only available to prousers but\n",
      "[22:44] basically that model is capable of\n",
      "[22:47] surfing the web interacting with guies\n",
      "[22:49] and doing things on your behalf. Okay,\n",
      "[22:52] so this was actually the first video in\n",
      "[22:54] a larger series on AI agents. So here\n",
      "[22:57] the discussion was relatively high\n",
      "[22:59] level. We didn't go into the technical\n",
      "[23:01] details or write any code. That's\n",
      "[23:03] because I just wanted to lay the\n",
      "[23:04] foundation for future videos where I'm\n",
      "[23:07] going to talk through each of these one\n",
      "[23:09] by one and build concrete examples of\n",
      "[23:12] each of them. And so in the next video\n",
      "[23:14] I'll be building a level one agentic\n",
      "[23:17] system. I haven't decided what I'm going\n",
      "[23:18] to build yet. So if you have any\n",
      "[23:19] suggestions let me know in the comment\n",
      "[23:21] section below. Also if there's anything\n",
      "[23:22] else you want me to cover in this series\n",
      "[23:24] let me know in the comments. The AI\n",
      "[23:26] agent space is massive and it's only\n",
      "[23:28] growing and I'm sure there's so many\n",
      "[23:30] tools and ideas out there that I'm\n",
      "[23:32] completely ignorant of. And so if\n",
      "[23:34] there's anything you keep seeing over\n",
      "[23:35] and over again and you think I should\n",
      "[23:36] cover, let me know. And with that, as\n",
      "[23:38] always, thank you so much for your time\n",
      "[23:39] and thanks for watching.]\n",
      "The video \"What Are AI Agents? (And Why They're a Big Deal)\" on YouTube is an introductory overview about AI agents, intended as the first in a larger series on the topic. Here’s a summary of what the video covers:\n",
      "\n",
      "## Main Points:\n",
      "\n",
      "1. **What Is an AI Agent?**\n",
      "   - The video discusses the ambiguity and variety in definitions of AI agents from major organizations such as OpenAI, Hugging Face, and Anthropic.\n",
      "   - Common elements across definitions include the use of large language models (LLMs), tool use, and autonomy.\n",
      "\n",
      "2. **Why Should We Care About AI Agents?**\n",
      "   - The speaker highlights that 2025 is being called the “year of AI agents.”\n",
      "   - AI agents are distinguished from basic chatbots because they can interact with real-world tools (Python interpreter, web browsing, emails, etc.) and can operate with greater autonomy and reasoning.\n",
      "\n",
      "3. **Key Features of Agents:**\n",
      "   - Use of LLMs (like GPT) as a core.\n",
      "   - Integration with tools (code execution, web search, APIs, memory, GUIs).\n",
      "   - Degree of autonomy and planning capabilities (“agency” exists on a spectrum).\n",
      "\n",
      "4. **Three Levels of Agency:**\n",
      "   - **Level 1: LLM + Tools**: Basic mode where an LLM can use tools (like web search and code).\n",
      "   - **Level 2: LLM Workflows**: Multi-step processes and workflows using several LLMs and tools, breaking down complex tasks (like email sorting and writing).\n",
      "   - **Level 3: LLM in a Loop**: Systems where LLMs receive feedback and iteratively improve their output, either through explicit feedback loops or by updating model parameters (reinforcement learning).\n",
      "\n",
      "5. **Design Patterns for Agentic Systems:**\n",
      "   - Chaining (sequential steps), routing (conditional forks), parallelization (doing subtasks at once), orchestrator/worker (planning and delegation), and evaluator/optimizer (feedback loop).\n",
      "\n",
      "6. **Why Agents are More Valuable Than Chatbots:**\n",
      "   - Agents can act in the real world, break down and solve more complex tasks, and improve over time using feedback.\n",
      "   - Recent advances in reasoning and “test time compute scaling” make agents more effective.\n",
      "\n",
      "7. **What’s Next in the Series:**\n",
      "   - The creator plans to delve deeper into building concrete examples of these systems in future videos.\n",
      "\n",
      "## Summary Statement\n",
      "\n",
      "The video is an introductory, high-level explainer meant for people interested in understanding what AI agents are, why they matter, what makes them distinct from simple chatbots, and how the concept of \"agency\" in AI spans a spectrum from simple tool use to autonomous, iterative learning systems. The series will eventually show practical coding examples and system builds.\n",
      "\n",
      "If you have a more specific question or want a particular part broken down (e.g., the technical details or practical applications), let me know!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " >  Write video chapters for the youtube video\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent updated: YouTube Transcript Agent]\n",
      "Certainly! Here are suggested video chapters for “What Are AI Agents? (And Why They're a Big Deal)” based on the transcript:\n",
      "\n",
      "---\n",
      "\n",
      "**00:00 - Introduction**\n",
      "- Overview of video series on AI agents and what will be covered in this episode.\n",
      "\n",
      "**00:36 - Defining AI Agents**\n",
      "- How different organizations (OpenAI, Hugging Face, Anthropic) define AI agents.\n",
      "\n",
      "**02:00 - Common Features of AI Agents**\n",
      "- Key elements shared across definitions: LLMs, tool use, autonomy.\n",
      "\n",
      "**03:39 - Why Care About AI Agents?**\n",
      "- AI agents compared to chatbots; why 2025 may be the year of AI agents.\n",
      "\n",
      "**04:40 - Agents vs. Chatbots: Real-World Interaction**\n",
      "- Limitations of LLMs alone and how tool use enables real-world actions.\n",
      "\n",
      "**05:34 - Test-Time Compute & Reasoning Models**\n",
      "- Recent advances in reasoning capabilities and their impact on AI agents.\n",
      "\n",
      "**06:36 - The Spectrum of Agency**\n",
      "- Introduction of agency levels and how systems vary in autonomy and complexity.\n",
      "\n",
      "**07:10 - Level 1: LLM + Tools**\n",
      "- Basic agentic system: LLMs equipped with tools, their use cases, and limitations.\n",
      "\n",
      "**11:28 - Level 2: LLM Workflows**\n",
      "- Multi-step workflows; how combining models and processes solves more complex tasks.\n",
      "\n",
      "**14:12 - Agentic System Design Patterns**\n",
      "- Common design paradigms: chaining, routing, parallelization, orchestrator/workers, evaluator/optimizer.\n",
      "\n",
      "**19:06 - Level 3: LLM in a Loop**\n",
      "- Feedback-driven agents; iterative improvement and real-world applications.\n",
      "\n",
      "**21:43 - Reinforcement Learning and Parameter Updates**\n",
      "- Agents that learn and improve through real-world feedback and fine-tuning.\n",
      "\n",
      "**22:52 - Closing and Series Overview**\n",
      "- Summary, what's next in the series, and call for viewer suggestions.\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you need timestamp adjustments or a more condensed version for YouTube’s description box!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " >  Write me a 3 line summary of LLM in a loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Agent updated: YouTube Transcript Agent]\n",
      "\"LLM in a loop\" refers to an AI agent design where a large language model (LLM) repeatedly generates outputs and receives feedback, refining its responses in each cycle. This closed-loop approach allows the LLM to improve its performance and better meet user requirements through multiple iterations. Such systems can tackle open-ended tasks with more autonomy, adapting based on real-world results or feedback.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " >  exit\n"
     ]
    }
   ],
   "source": [
    "await main()\n",
    "# what is this video about? https://youtu.be/ZaY5_ScmiFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04db1009-db50-490f-99d9-4347d2763b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to run in a .py script use\n",
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
