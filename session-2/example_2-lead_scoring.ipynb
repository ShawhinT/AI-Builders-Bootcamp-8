{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f0d488b-7772-4633-8449-2592a6bc080b",
   "metadata": {},
   "source": [
    "# Lead Scoring with GPT-4.1\n",
    "## ABB #8 - Session 2\n",
    "\n",
    "Code authored by: Shaw Talebi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae237b-2af5-4c82-9f19-6f3d3a4ae892",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dfd12b5-0f02-4570-991f-bf8c575487c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9b4434-9dec-4051-b4b0-98684be0b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vars from .env\n",
    "load_dotenv()\n",
    "\n",
    "# connect to openai API\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2edc30b-7fcf-49ce-a7e8-fa7b29d59ce1",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23833b70-3905-4f3d-aa8d-d74b4d6e771b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_one_hot_features_aligned(df_train, df_test):\n",
    "    \"\"\"Create one-hot encoded features ensuring train and test have identical columns.\n",
    "    \n",
    "    This function concatenates train and test data, applies one-hot encoding to ensure\n",
    "    all categories are captured, then splits them back to maintain consistent features.\n",
    "    \n",
    "    Args:\n",
    "        df_train: Training DataFrame\n",
    "        df_test: Test DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (df_train_encoded, df_test_encoded) with identical columns\n",
    "    \"\"\"\n",
    "    # Define columns to encode\n",
    "    columns_to_encode = [\n",
    "        'Lead Origin',\n",
    "        'Lead Source', \n",
    "        'What is your current occupation',\n",
    "        'Last Activity',\n",
    "        'Tags'\n",
    "    ]\n",
    "    \n",
    "    # Store original sizes\n",
    "    train_size = len(df_train)\n",
    "    \n",
    "    # Concatenate train and test\n",
    "    df_combined = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "    \n",
    "    # Apply one-hot encoding to combined data\n",
    "    df_combined_encoded = pd.get_dummies(\n",
    "        df_combined,\n",
    "        columns=columns_to_encode,\n",
    "        prefix=['LeadOrigin', 'LeadSource', 'Occupation', 'Last Activity','Tags'],\n",
    "        drop_first=False\n",
    "    )\n",
    "    \n",
    "    # Split back into train and test\n",
    "    df_train_encoded = df_combined_encoded.iloc[:train_size].reset_index(drop=True)\n",
    "    df_test_encoded = df_combined_encoded.iloc[train_size:].reset_index(drop=True)\n",
    "    \n",
    "    return df_train_encoded, df_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14134185-4b44-4497-8e54-411af0ad1ef5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def format_input_data(record) -> str:\n",
    "    return f\"\"\"Lead Origin: {record['Lead Origin']}\n",
    "Lead Source: {record['Lead Source']}\n",
    "Last Activity: {record['Last Activity']}\n",
    "Tags: {record['Tags']}\n",
    "Current Occupation: {record['What is your current occupation']}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d159887-8c1b-439f-99b4-d75039d9ecf4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_true_label(record) -> int:\n",
    "    return record['Converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc58cd2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_prompt(filename, **kwargs) -> str:\n",
    "    \"\"\"Load text from a markdown file in the prompts directory and format with variables.\"\"\"\n",
    "    with open(f\"prompts/{filename}.md\", \"r\") as f:\n",
    "        return f.read().format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8baed1f4-8791-41bd-b04c-25ee18081ce8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_prediction(model_name, prompt, lead_data, data_model) -> int:\n",
    "    # generate prediction\n",
    "    response = client.responses.parse(\n",
    "        model=model_name,\n",
    "        instructions=prompt,\n",
    "        input=lead_data,\n",
    "        text_format=data_model,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # return label\n",
    "    return response.output_parsed.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9efc66a-80d2-4234-84a2-e3bf0ea06bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeadScore(BaseModel):\n",
    "    label: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8683993-ff67-4030-8227-b13729dab775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(num_examples) -> str:  \n",
    "    # format examples\n",
    "    examples = ''\n",
    "    \n",
    "    # generate random integers to index train data\n",
    "    np.random.seed(42)\n",
    "    random_indices = np.random.choice(len(train_data), size=num_examples, replace=False)\n",
    "    \n",
    "    for i in random_indices:\n",
    "        # input\n",
    "        examples += f'<user_input id=\"example-{i}\">\\n'\n",
    "        examples += f'{format_input_data(train_data[i])}\\n'\n",
    "        examples += f'</user_input id=\"example-{i}\">\\n\\n'\n",
    "        \n",
    "        # output\n",
    "        examples += f'<ground_truth_label id=\"example-{i}\">\\n'\n",
    "        examples += f'{get_true_label(train_data[i])}\\n'\n",
    "        examples += f'</ground_truth_label id=\"example-{i}\">\\n\\n'\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8b1b1-7227-4a16-81b8-35999dde0785",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb001bf4-55ac-4b28-bfa3-c6e513233ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lead scoring data\n",
    "dataset = load_dataset(\"shawhin/lead-scoring-x\")\n",
    "\n",
    "train_data = dataset['train'] # few-shot examples\n",
    "valid_data = dataset['valid'] # crafting prompt\n",
    "train_ml_data = dataset['test'] # evaluating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ff290-7305-44c2-98ea-40aa0688f224",
   "metadata": {},
   "source": [
    "### Baseline: ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d58aac5-6a01-4926-bb5e-ffa196f61207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = create_one_hot_features_aligned(train_ml_data.to_pandas(), valid_data.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "034bca37-61ec-4fe1-8a10-e8549375ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data by predictors and target\n",
    "X_train = df_train.iloc[:, 4:]\n",
    "y_train = df_train['Converted']\n",
    "\n",
    "X_test = df_valid.iloc[:, 4:]\n",
    "y_test = df_valid['Converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b3223d-7902-444a-8db0-81be98e1a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression model\n",
    "clf = LogisticRegression(random_state=0).fit(X_train.iloc[:15, :], y_train.iloc[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f1a6e5d-283e-4cec-9394-9cde00402a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828582584927762\n",
      "0.8577569363032435\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "train_acc = clf.score(X_train, y_train)\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "\n",
    "print(train_acc)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13688888-61de-4c94-9daf-41424c1cd914",
   "metadata": {},
   "source": [
    "### Prompt 1: Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00cc37-13fd-4c12-bb9f-4bb94269cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_input_data(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ff9a6-6556-4756-8de2-396e40e6f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_true_label(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ee471-e634-405c-9775-762181e515c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_leads=30\n",
    "model_name = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c5bd7-9181-41e0-abfc-e69a778a8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = load_prompt('prompt-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce513563-c28d-4589-9cf4-aeb6de4ec73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt_1_pred = []\n",
    "\n",
    "for i in range(num_leads):\n",
    "    # generate prediction\n",
    "    response = client.responses.parse(\n",
    "        model=model_name,\n",
    "        instructions=prompt_1,\n",
    "        input=format_input_data(valid_data[i]),\n",
    "        text_format=LeadScore,\n",
    "    )\n",
    "\n",
    "    # add prediction to list\n",
    "    prompt_1_pred.append(response.output_parsed.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07a615-85bb-409e-8495-0dc71f1a8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df to store results\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# save results to df\n",
    "df_results['true_label'] = get_true_label(valid_data[:num_leads])\n",
    "df_results['prompt_1_pred'] = prompt_1_pred\n",
    "df_results['prompt_1_correct'] = df_results['true_label']==df_results['prompt_1_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07f18b-5d3b-4bec-bfe6-d29846667154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy\n",
    "print(df_results['prompt_1_correct'].sum()/len(df_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d1b98-f8aa-42bf-b558-4fd33d43b511",
   "metadata": {},
   "source": [
    "### Prompt 2: Meta-prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6039887f-4d50-45a9-aafd-8c1603b0db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = load_prompt('prompt-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0cfe73-6413-42d6-975a-ce7feff3f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt_2_pred = []\n",
    "\n",
    "for i in range(num_leads):\n",
    "    # generate prediction\n",
    "    label = generate_prediction(\n",
    "        model_name, \n",
    "        prompt_2, \n",
    "        format_input_data(valid_data[i]), \n",
    "        LeadScore,\n",
    "    )\n",
    "\n",
    "    # add prediction to list\n",
    "    prompt_2_pred.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a73ee-ee46-46d5-bcf6-778beb86f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to df\n",
    "df_results['prompt_2_pred'] = prompt_2_pred\n",
    "df_results['prompt_2_correct'] = df_results['true_label']==df_results['prompt_2_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f518f20c-e5db-47ee-94c5-92289ba77e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy\n",
    "print(df_results['prompt_2_correct'].sum()/len(df_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c41c484-5ad3-4730-aba7-9cfdc1f35b0b",
   "metadata": {},
   "source": [
    "### Prompt 3: Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff714eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate few-shot examples\n",
    "examples = generate_examples(15)\n",
    "\n",
    "# generate prompt\n",
    "prompt_3 = load_prompt('prompt-3', examples=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f1ca2-64b1-400e-b2ad-50728d777a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(prompt_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3234de-228e-47f8-adde-3493cd7eaad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt_3_pred = []\n",
    "\n",
    "for i in range(num_leads):\n",
    "    # generate prediction\n",
    "    label = generate_prediction(\n",
    "        model_name, \n",
    "        prompt_3, \n",
    "        format_input_data(valid_data[i]), \n",
    "        LeadScore,\n",
    "    )\n",
    "\n",
    "    # add prediction to list\n",
    "    prompt_3_pred.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415360bd-b622-4a35-b8e3-b1841509fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to df\n",
    "df_results['prompt_3_pred'] = prompt_3_pred\n",
    "df_results['prompt_3_correct'] = df_results['true_label']==df_results['prompt_3_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92127753-826e-4a2f-a68c-7be2ea443853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy\n",
    "print(df_results['prompt_3_correct'].sum()/len(df_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b75d9-6298-4131-be65-091313c47a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
